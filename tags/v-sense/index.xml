<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>V Sense on Martin Alain</title>
    <link>https://malain35.github.io/tags/v-sense/</link>
    <description>Recent content in V Sense on Martin Alain</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2024 Martin Alain</copyright>
    <lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/v-sense/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>V-SENSE</title>
      <link>https://malain35.github.io/project/v-sense/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://malain35.github.io/project/v-sense/</guid>
      <description>

&lt;h2 id=&#34;extending-visual-sensation-through-image-based-visual-computing&#34;&gt;Extending Visual Sensation through Image-Based Visual Computing&lt;/h2&gt;

&lt;p&gt;Since September 2016, I am a research fellow in the &lt;a href=&#34;https://v-sense.scss.tcd.ie/&#34; target=&#34;_blank&#34;&gt;V-SENSE project&lt;/a&gt;, lead by Professor &lt;a href=&#34;https://www.scss.tcd.ie/Aljosa.Smolic/&#34; target=&#34;_blank&#34;&gt;Aljosa Smolic&lt;/a&gt;.
V-SENSE is a team of 20+ researchers (half postdocs half PhDs) in Visual Computing at the intersection of Computer Vision, Computer Graphics and Media Signal Processing.
My research is focused on light field imaging technologies, investigating novel methods for light field denoising, scene reconstruction from light field, and light field rendering.&lt;/p&gt;

&lt;h2 id=&#34;light-fields-imaging-technologies&#34;&gt;Light fields imaging technologies&lt;/h2&gt;

&lt;p&gt;Light fields capture all light rays passing through a given volume of space.
Compared to traditional 2D imaging systems which capture the spatial intensity of the light rays, the 4D light fields also contain the angular direction of light rays.
This additional information allows for multiple applications in different research areas such as image processing, computer vision, and computer graphics, including (but not limited to) the reconstruction of the 3D geometry of a scene, creating new images from virtual point of view, or changing the focus of an image after it is captured.
Light fields are also a growing topic of interest in the VR/AR community.&lt;/p&gt;

&lt;p&gt;Below is an example of a light field captured with a Lytro Illum camera, which allows for refocusing and changing the perspective.&lt;/p&gt;

&lt;iframe width=&#39;809&#39; height=&#39;540&#39; src=&#39;https://v-sense.scss.tcd.ie/wp-content/uploads/2017/06/Lytro_example.mp4?_=1&#39; frameborder=&#39;0&#39; allowfullscreen scrolling=&#39;no&#39;&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;related-publications&#34;&gt;Related publications&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/fast-and-accurate-optical-flow-based-depth-map-estimation-from-light-fields/&#34; target=&#34;_blank&#34;&gt;Fast and Accurate Optical Flow based Depth Map Estimation from Light Fields&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/light_field_denoising_by_sparse_5d_transform_domain_collaborative_filtering/&#34; target=&#34;_blank&#34;&gt;Light Field Denoising by Sparse 5D Transform Domain Collaborative Filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/light_field_super_resolution_via_lfbm5d_sparse_coding/&#34; target=&#34;_blank&#34;&gt;Light Field Super-Resolution via LFBM5D Sparse Coding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/a_pipeline_for_lenslet_light_field_quality_enhancement/&#34; target=&#34;_blank&#34;&gt;A Pipeline for Lenslet Light Field Quality Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/interactive_light_field_tilt-shift_refocus/&#34; target=&#34;_blank&#34;&gt;Interactive Light Field Tilt-Shift Refocus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/a_study_of_light_field_streaming_for_interactive_refocusing/&#34; target=&#34;_blank&#34;&gt;A Study of Light Field Streaming for Interactive Refocusing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/self-supervised_light_field_view_synthesis_using_cycle_consistency/&#34; target=&#34;_blank&#34;&gt;Self-supervised light field view synthesis using cycle consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/a_spatio-angular_binary_descriptor_for_fast_light_field_inter_view_matching/&#34; target=&#34;_blank&#34;&gt;A Spatio-Angular Binary Descriptor for Fast Light Field Inter View Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/light_field_style_transfer_with_local_angular_consistency/&#34; target=&#34;_blank&#34;&gt;Light Field Style Transfer With Local Angular Consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/focus_guided_light_field_saliency_estimation/&#34; target=&#34;_blank&#34;&gt;Focus Guided Light Field Saliency Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://malain35.github.io/publication/a_spatio-angular_filter_for_high_quality_sparse_light_field_refocusing/&#34; target=&#34;_blank&#34;&gt;A Spatio-Angular Filter for High Quality Sparse Light Field Refocusing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
